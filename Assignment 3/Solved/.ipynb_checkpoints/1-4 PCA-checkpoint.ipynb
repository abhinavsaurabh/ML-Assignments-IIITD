{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhinavsaurabh/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator SVC from version 0.22.2.post1 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "filename = 'GridSearchCv/1-3 PCA SVM rbf C=10.sav'\n",
    "SVM = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR = 'cifar-10-batches-py/'\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file,'rb') as fo:\n",
    "        cifar_dict = pickle.load(fo,encoding='bytes')\n",
    "    return cifar_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = ['batches.meta','data_batch_1','data_batch_2','data_batch_3','data_batch_4','data_batch_5','test_batch']\n",
    "\n",
    "all_data = [0,1,2,3,4,5,6]\n",
    "\n",
    "for i, direc in zip(all_data,dirs):\n",
    "    all_data[i] = unpickle(CIFAR+direc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_meta = all_data[0]\n",
    "data_batch1 = all_data[1]\n",
    "data_batch2 = all_data[2]\n",
    "data_batch3 = all_data[3]\n",
    "data_batch4 = all_data[4]\n",
    "data_batch5 = all_data[5]\n",
    "test_batch = all_data[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_batches = [data_batch1,data_batch2,data_batch3,data_batch4,data_batch5]\n",
    "test_batch1 = [test_batch]\n",
    "#all_train_batches = [data_batch1]\n",
    "#all_train_batches1 = all_train_batches[:1000]\n",
    "training_image = np.vstack([d[b\"data\"] for d in all_train_batches])\n",
    "train_len = len(training_image)\n",
    "training_image = training_image.reshape(train_len,3*32*32)\n",
    "training_label = np.hstack([d[b\"labels\"] for d in all_train_batches])\n",
    "training_label = training_label.reshape(50000)\n",
    "\n",
    "#temp = training_image[:100]\n",
    "#temp_2  = training_label[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = np.vstack([d[b\"data\"] for d in test_batch1])\n",
    "test_len = len(test_image)\n",
    "test_image = test_image.reshape(test_len,3*32*32)\n",
    "test_label = np.hstack([d[b\"labels\"] for d in test_batch1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(.90)\n",
    "X_train = pca.fit_transform(training_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = 'PCA Xtrain Xtest/XtrainPCA50000.sav'\n",
    "X_train = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'PCA Xtrain Xtest/XtestPCA10000.sav'\n",
    "X_test = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43571, 99)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM.support_vectors_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "newSVM = SVM.support_vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_ind = SVM.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_m2 = X_train[SVM.support_]\n",
    "y_m2 = training_label[SVM.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43571,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_m2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, random_state=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "classifier = SVC(kernel ='rbf', random_state = 0,C=10) \n",
    " # training set in x, y axis \n",
    "classifier.fit(x_m2, y_m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '1-4 PCA classifier.sav'\n",
    "pickle.dump(classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43563, 99)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.support_vectors_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpredict = classifier.predict(x_m2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpredict = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91      4094\n",
      "           1       0.99      0.97      0.98      4072\n",
      "           2       0.82      0.85      0.83      4743\n",
      "           3       0.95      0.90      0.92      4896\n",
      "           4       0.82      0.86      0.84      4626\n",
      "           5       0.96      0.89      0.93      4711\n",
      "           6       0.84      0.91      0.87      4266\n",
      "           7       0.97      0.92      0.94      4070\n",
      "           8       0.93      0.95      0.94      3740\n",
      "           9       0.99      0.97      0.98      4353\n",
      "\n",
      "    accuracy                           0.91     43571\n",
      "   macro avg       0.92      0.91      0.91     43571\n",
      "weighted avg       0.91      0.91      0.91     43571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_m2, trainpredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.65      0.63      1000\n",
      "           1       0.65      0.68      0.67      1000\n",
      "           2       0.44      0.46      0.45      1000\n",
      "           3       0.38      0.39      0.38      1000\n",
      "           4       0.50      0.49      0.50      1000\n",
      "           5       0.50      0.47      0.48      1000\n",
      "           6       0.59      0.63      0.61      1000\n",
      "           7       0.67      0.58      0.62      1000\n",
      "           8       0.68      0.67      0.68      1000\n",
      "           9       0.62      0.59      0.60      1000\n",
      "\n",
      "    accuracy                           0.56     10000\n",
      "   macro avg       0.56      0.56      0.56     10000\n",
      "weighted avg       0.56      0.56      0.56     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_label, testpredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
