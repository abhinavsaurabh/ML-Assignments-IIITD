{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhinavsaurabh/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator SVC from version 0.22.2.post1 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "filename = 'GridSearchCv/1-3 HOG SVM scaled rbf C=10.sav'\n",
    "SVM = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR = 'cifar-10-batches-py/'\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file,'rb') as fo:\n",
    "        cifar_dict = pickle.load(fo,encoding='bytes')\n",
    "    return cifar_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = ['batches.meta','data_batch_1','data_batch_2','data_batch_3','data_batch_4','data_batch_5','test_batch']\n",
    "\n",
    "all_data = [0,1,2,3,4,5,6]\n",
    "\n",
    "for i, direc in zip(all_data,dirs):\n",
    "    all_data[i] = unpickle(CIFAR+direc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_meta = all_data[0]\n",
    "data_batch1 = all_data[1]\n",
    "data_batch2 = all_data[2]\n",
    "data_batch3 = all_data[3]\n",
    "data_batch4 = all_data[4]\n",
    "data_batch5 = all_data[5]\n",
    "test_batch = all_data[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_batches = [data_batch1,data_batch2,data_batch3,data_batch4,data_batch5]\n",
    "test_batch1 = [test_batch]\n",
    "#all_train_batches = [data_batch1]\n",
    "#all_train_batches1 = all_train_batches[:1000]\n",
    "training_image = np.vstack([d[b\"data\"] for d in all_train_batches])\n",
    "train_len = len(training_image)\n",
    "training_image = training_image.reshape(train_len,3*32*32)\n",
    "training_label = np.hstack([d[b\"labels\"] for d in all_train_batches])\n",
    "training_label = training_label.reshape(50000)\n",
    "\n",
    "#temp = training_image[:100]\n",
    "#temp_2  = training_label[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = np.vstack([d[b\"data\"] for d in test_batch1])\n",
    "test_len = len(test_image)\n",
    "test_image = test_image.reshape(test_len,3*32*32)\n",
    "test_label = np.hstack([d[b\"labels\"] for d in test_batch1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.colors as colors\n",
    "from skimage.feature import hog\n",
    "from skimage import color\n",
    "\n",
    "X_train_hog = []\n",
    "\n",
    "for img in training_image:\n",
    "\n",
    "    img = np.reshape(img.T,(32,32,3))\n",
    "    # color histogram\n",
    "    array=np.asarray(img)\n",
    "    arr=(array.astype(float))/255.0\n",
    "    img_hsv = colors.rgb_to_hsv(arr[...,:3])\n",
    "    img_color_hist = np.histogram(img_hsv[...,0],bins=10)\n",
    "    hist_values = img_color_hist[0]\n",
    "\n",
    "    #hog\n",
    "    gray_image = color.rgb2gray(img)\n",
    "    hog_feature = hog(gray_image,orientations=8, pixels_per_cell=(8, 8), cells_per_block=(1, 1))\n",
    "\n",
    "    #joined\n",
    "    X_train_hog.append(np.concatenate((hist_values,hog_feature),axis=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_hog = []\n",
    "\n",
    "for img in test_image:\n",
    "\n",
    "    img = np.reshape(img.T,(32,32,3))\n",
    "    # color histogram\n",
    "    array=np.asarray(img)\n",
    "    arr=(array.astype(float))/255.0\n",
    "    img_hsv = colors.rgb_to_hsv(arr[...,:3])\n",
    "    img_color_hist = np.histogram(img_hsv[...,0],bins=10)\n",
    "    hist_values = img_color_hist[0]\n",
    "\n",
    "    #hog\n",
    "    gray_image = color.rgb2gray(img)\n",
    "    hog_feature = hog(gray_image,orientations=8, pixels_per_cell=(8, 8), cells_per_block=(1, 1))\n",
    "\n",
    "    #joined\n",
    "    X_test_hog.append(np.concatenate((hist_values,hog_feature),axis=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "X_train =numpy.asarray(X_train_hog)\n",
    "X_test = numpy.asarray(X_test_hog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'XTrain_HOG 50000.sav'\n",
    "pickle.dump(X_train, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'XTest_HOG 10000.sav'\n",
    "pickle.dump(X_test, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'XTrain_HOG 50000.sav'\n",
    "X_train = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'XTest_HOG 10000.sav'\n",
    "X_test = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "X_train = preprocessing.scale(X_train)\n",
    "X_test = preprocessing.scale(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 138)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48970, 138)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM.support_vectors_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_m2 = X_train[SVM.support_]\n",
    "y_m2 = training_label[SVM.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, random_state=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "classifier = SVC(kernel ='rbf', random_state = 0,C=10) \n",
    " # training set in x, y axis \n",
    "classifier.fit(x_m2, y_m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '1-4 HOG classifier.sav'\n",
    "pickle.dump(classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpredict = classifier.predict(x_m2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpredict = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      4872\n",
      "           1       0.96      0.98      0.97      4847\n",
      "           2       0.99      0.95      0.97      4968\n",
      "           3       0.96      0.95      0.96      4991\n",
      "           4       0.96      0.94      0.95      4914\n",
      "           5       0.94      0.96      0.95      4923\n",
      "           6       0.89      0.97      0.93      4648\n",
      "           7       0.97      0.96      0.97      4905\n",
      "           8       1.00      0.98      0.99      4938\n",
      "           9       0.97      0.96      0.97      4964\n",
      "\n",
      "    accuracy                           0.96     48970\n",
      "   macro avg       0.96      0.96      0.96     48970\n",
      "weighted avg       0.96      0.96      0.96     48970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_m2, trainpredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.49      0.46      1000\n",
      "           1       0.39      0.44      0.41      1000\n",
      "           2       0.31      0.27      0.29      1000\n",
      "           3       0.23      0.21      0.22      1000\n",
      "           4       0.34      0.32      0.33      1000\n",
      "           5       0.32      0.33      0.32      1000\n",
      "           6       0.42      0.44      0.43      1000\n",
      "           7       0.32      0.30      0.31      1000\n",
      "           8       0.44      0.45      0.45      1000\n",
      "           9       0.30      0.28      0.29      1000\n",
      "\n",
      "    accuracy                           0.35     10000\n",
      "   macro avg       0.35      0.35      0.35     10000\n",
      "weighted avg       0.35      0.35      0.35     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_label, testpredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
