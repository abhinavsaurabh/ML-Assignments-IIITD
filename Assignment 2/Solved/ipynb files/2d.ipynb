{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegression(object):\n",
    "    \"\"\"docstring for LogRegression.\"\"\"\n",
    "    def __init__(self, learning_rate=0.001, n_iters=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    \"\"\"You can give any required inputs to the fit()\"\"\"\n",
    "    def fit(self, X,X_test, y):\n",
    "        \n",
    "\n",
    "        \"\"\"Write it from scratch. Usage of sklearn is not allowed\"\"\"\n",
    "        n_sam, n_feat = X.shape\n",
    "\n",
    "        self.weights = np.zeros(n_feat)\n",
    "        self.bias = 0\n",
    "        losslist=0\n",
    "        acclist = 0\n",
    "   \n",
    "        \n",
    "        self.weights = self.regularisation(X,X_test,y)\n",
    "        for _ in range(self.n_iters):\n",
    "       \n",
    "            linear_model = np.dot(X, self.weights) + self.bias\n",
    "    \n",
    "            y_predicted = self._sigmoid(linear_model)\n",
    "\n",
    "      \n",
    "            dw = (1 / n_sam) * np.dot(X.T, (y_predicted - y))\n",
    "            db = (1 / n_sam) * np.sum(y_predicted - y)\n",
    "       \n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias -= self.lr * db\n",
    "            \n",
    "\n",
    "            z = np.dot(X, self.weights)\n",
    "            h = self._sigmoid(z)\n",
    "            losslist = np.append(losslist,(self.lossf(h, y)))\n",
    "            \n",
    "            y_pred = self.predict(X)\n",
    "            acclist= np.append(acclist,self.acc(y,y_pred))\n",
    "            \n",
    "        return losslist,acclist\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "    \"\"\" You can add as many methods according to your requirements, but training must be using fit(), and testing must be with predict()\"\"\"\n",
    "    def predict(self, X):\n",
    "               \n",
    "        \"\"\"Write it from scratch. Usage of sklearn is not allowed\"\"\"\n",
    "\n",
    "        \"\"\"Fill your code here. predict() should only take X_test and return predictions.\"\"\"\n",
    "        linear_model = np.dot(X, self.weights) + self.bias\n",
    "        ypred = self._sigmoid(linear_model)\n",
    "        y_predicted_cls = [1 if i > 0.5 else 0 for i in ypred]\n",
    "        return np.array(y_predicted_cls)\n",
    "    \n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def lossf(self,h,y):\n",
    "        #n = len(ypred)\n",
    "        #self.loss=0\n",
    "        #for i in range(n):\n",
    "           # self.loss = np.append(self.loss, [-y[i]*np.log(ypred[i])-(1-y[i])*np.log(1-ypred[i])])\n",
    "        #print(self.loss)\n",
    "        #loss = np.mean(self.loss)\n",
    "        return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
    "        #return loss    \n",
    "        \n",
    "    def acc(self,y,ypred):\n",
    "        size=ypred.size\n",
    "        count=0\n",
    "        for j in range(ypred.size):\n",
    "            if ypred[j]==y[j]:\n",
    "                count+=1;\n",
    "        return (count/ypred.size) \n",
    "            \n",
    "    def regularisation(self,X_train,X_test,y_train):\n",
    "        for i in range(1,self.n_iters):\n",
    "            a = np.dot(X_train,self.weights) \n",
    "            at = np.dot(X_test,self.weights)\n",
    "            b = self._sigmoid(a)\n",
    "            bt = self._sigmoid(at)\n",
    "            cr = np.dot(X_train.T, (b - y_train)) / y_train.size\n",
    "            r = (l/(y_train.size))*(self.weights[1:].T @ self.weights[1:])\n",
    "            cr [1:] = cr[1:] + r\n",
    "            self.weights = self.weights - self.lr*gr\n",
    "        return self.weights    \n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_split(Z):\n",
    "    f = Z.shape[0]//5\n",
    "    fold1=Z[:f]\n",
    "    fold2=Z[f:(2*f)]\n",
    "    fold3=Z[(2*f):(3*f)]\n",
    "    fold4=Z[(3*f):(4*f)]\n",
    "    fold5=Z[(4*f):]\n",
    "    return fold1,fold2,fold3,fold4,fold5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def main() :\n",
    "data1 = loadmat('dataset_1.mat')\n",
    "data2 = data1['samples']\n",
    "mlabel = data1['labels'][0]\n",
    "data3 = np.column_stack((data2,mlabel))\n",
    "df = pd.DataFrame(data3)\n",
    "df.columns = [0, 1,'Labels']\n",
    "feature_cols = [0,1]\n",
    "target = ['Labels']\n",
    "X = df[feature_cols]\n",
    "Y = df[target]\n",
    "Xfold1,Xfold2,Xfold3,Xfold4,Xfold5 = fold_split(X)\n",
    "Yfold1,Yfold2,Yfold3,Yfold4,Yfold5 = fold_split(Y)\n",
    "    \n",
    "    #list1=[]\n",
    "    #iter = [0,200,400,600,800,1000]\n",
    "    #for i in range \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'l' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-5463a35d7ac9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdfY1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mYfold1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYfold2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYfold3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYfold4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdfY1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfY1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mloss_trlist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccu_trlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfX1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXfold5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfY1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mY_train1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfX1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-9d172bae0193>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, X_test, y)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# gradient descent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregularisation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# approximate y with linear combination of weights and x, plus bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-9d172bae0193>\u001b[0m in \u001b[0;36mregularisation\u001b[0;34m(self, X_train, X_test, y_train)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mht\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0mgr\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'l' is not defined"
     ]
    }
   ],
   "source": [
    "model1 = LogRegression(0.001,1000)\n",
    "dfX1 = pd.concat([Xfold1,Xfold2,Xfold3,Xfold4], ignore_index=True)\n",
    "dfY1 = pd.concat([Yfold1,Yfold2,Yfold3,Yfold4], ignore_index=True,axis=0)\n",
    "dfY1 = dfY1.to_numpy().reshape(4000)\n",
    "loss_trlist,accu_trlist = model1.fit(dfX1.to_numpy(),Xfold5.values, dfY1)\n",
    "\n",
    "Y_train1 = model1.predict(dfX1.to_numpy())\n",
    "Y_pred1 = model1.predict(Xfold5.to_numpy())\n",
    "\n",
    "Y5 = Yfold5\n",
    "Y5 = Y5.to_numpy().reshape(1000)\n",
    "loss_tslist,accu_tslist = model1.fit(Xfold5.values,Y5)\n",
    "\n",
    "i = np.arange(0, 1001, 1)\n",
    "\n",
    "\n",
    "#np.array(losslist,dtype=float)\n",
    "folddf1 = np.column_stack((i,loss_trlist,loss_tslist,accu_trlist,accu_tslist))\n",
    "folddf1 = pd.DataFrame(folddf1)\n",
    "folddf1.columns = [0, 1,2,3,4]\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(10)\n",
    "ax1.plot(folddf1[0],folddf1[1],label = \"TRAIN LOSS\") \n",
    "ax1.plot(folddf1[0],folddf1[2],label = \"TEST LOSS\")\n",
    "ax1.set_title('LOSS v/s Iteration')    \n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(folddf1[0],folddf1[3],label = \"TRAIN Accuracy\") \n",
    "ax2.plot(folddf1[0],folddf1[4],label = \"TEST Accuracy\")\n",
    "ax2.set_title('Accuracy v/s Iteration')   \n",
    "ax2.set_xlabel('Iteration')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "fig.suptitle('For Fold 5') \n",
    "    \n",
    "    #loss1train = model.lossf(dfY1,Y_train1)\n",
    "    #loss1test = model.lossf(Yfold5,Y_pred1)\n",
    "    #acc1train = model.lossf(dfY1,Y_train1)\n",
    "    #acc1test = model.lossf(Yfold5,Y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = LogRegression(0.001,1000)\n",
    "dfX2 = pd.concat([Xfold2,Xfold3,Xfold4,Xfold5], ignore_index=True)\n",
    "dfY2 = pd.concat([Yfold2,Yfold3,Yfold4,Yfold5], ignore_index=True)\n",
    "dfY2 = dfY2.to_numpy().reshape(4000)\n",
    "loss_trlist,accu_trlist = model2.fit(dfX2.to_numpy(), dfY2)\n",
    "\n",
    "Y_train2 = model2.predict(dfX2.to_numpy())\n",
    "Y_pred2 = model2.predict(Xfold1.to_numpy())\n",
    "\n",
    "\n",
    "Y1 = Yfold1\n",
    "Y1 = Y1.to_numpy().reshape(1000)\n",
    "loss_tslist,accu_tslist = model2.fit(Xfold1.values,Y1)\n",
    "\n",
    "#i = np.arange(0, 1001, 1)\n",
    "\n",
    "\n",
    "#np.array(losslist,dtype=float)\n",
    "folddf2 = np.column_stack((i,loss_trlist,loss_tslist,accu_trlist,accu_tslist))\n",
    "folddf2 = pd.DataFrame(folddf1)\n",
    "folddf2.columns = [0, 1,2,3,4]\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(10)\n",
    "ax1.plot(folddf2[0],folddf2[1],label = \"TRAIN LOSS\") \n",
    "ax1.plot(folddf2[0],folddf2[2],label = \"TEST LOSS\")\n",
    "ax1.set_title('LOSS v/s Iteration')    \n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(folddf2[0],folddf2[3],label = \"TRAIN Accuracy\") \n",
    "ax2.plot(folddf2[0],folddf2[4],label = \"TEST Accuracy\")\n",
    "ax2.set_title('Accuracy v/s Iteration')   \n",
    "ax2.set_xlabel('Iteration')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "fig.suptitle('For Fold 1') \n",
    "#loss2train = model.lossf(dfY2,Y_train2)\n",
    "#loss2test = model.lossf(Yfold1,Y_pred2)\n",
    "#acc2train = model.acc(dfY2,Y_train2)\n",
    "#acc2test = model.acc(Yfold1,Y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = LogRegression(0.001,1000)\n",
    "dfX3 = pd.concat([Xfold3,Xfold4,Xfold5,Xfold1], ignore_index=True)\n",
    "dfY3 = pd.concat([Yfold3,Yfold4,Yfold5,Yfold1], ignore_index=True)\n",
    "dfY3 = dfY3.to_numpy().reshape(4000)\n",
    "loss_trlist,accu_trlist = model3.fit(dfX3.to_numpy(), dfY3)\n",
    "Y_train3 = model3.predict(dfX3.to_numpy())\n",
    "Y_pred3 = model3.predict(Xfold2.to_numpy())\n",
    "\n",
    "Y2 = Yfold2\n",
    "Y2 = Y2.to_numpy().reshape(1000)\n",
    "loss_tslist,accu_tslist = model3.fit(Xfold2.values,Y2)\n",
    "\n",
    "folddf3 = np.column_stack((i,loss_trlist,loss_tslist,accu_trlist,accu_tslist))\n",
    "folddf3 = pd.DataFrame(folddf1)\n",
    "folddf3.columns = [0, 1,2,3,4]\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(10)\n",
    "ax1.plot(folddf3[0],folddf3[1],label = \"TRAIN LOSS\") \n",
    "ax1.plot(folddf3[0],folddf3[2],label = \"TEST LOSS\")\n",
    "ax1.set_title('LOSS v/s Iteration')    \n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(folddf3[0],folddf3[3],label = \"TRAIN Accuracy\") \n",
    "ax2.plot(folddf3[0],folddf3[4],label = \"TEST Accuracy\")\n",
    "ax2.set_title('Accuracy v/s Iteration')   \n",
    "ax2.set_xlabel('Iteration')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "fig.suptitle('For Fold 2') \n",
    "\n",
    "#loss3train = model.lossf(dfY3,Y_train3)\n",
    "#loss3test = model.lossf(Yfold2,Y_pred3)\n",
    "#acc3train = model.acc(dfY3,Y_train3)\n",
    "#acc3test = model.acc(Yfold2,Y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = LogRegression(0.001,1000)\n",
    "dfX4 = pd.concat([Xfold4,Xfold5,Xfold1,Xfold2], ignore_index=True)\n",
    "dfY4 = pd.concat([Yfold4,Yfold5,Yfold1,Yfold2], ignore_index=True)\n",
    "dfY4 = dfY4.to_numpy().reshape(4000)\n",
    "loss_trlist,accu_trlist = model4.fit(dfX4.to_numpy(), dfY4) \n",
    "Y_train4 = model4.predict(dfX4.to_numpy())\n",
    "Y_pred4 = model4.predict(Xfold3.to_numpy())\n",
    "\n",
    "\n",
    "Y3 = Yfold3\n",
    "Y3 = Y3.to_numpy().reshape(1000)\n",
    "loss_tslist,accu_tslist = model3.fit(Xfold3.values,Y3)\n",
    "\n",
    "folddf4 = np.column_stack((i,loss_trlist,loss_tslist,accu_trlist,accu_tslist))\n",
    "folddf4 = pd.DataFrame(folddf1)\n",
    "folddf4.columns = [0, 1,2,3,4]\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(10)\n",
    "ax1.plot(folddf4[0],folddf4[1],label = \"TRAIN LOSS\") \n",
    "ax1.plot(folddf4[0],folddf4[2],label = \"TEST LOSS\")\n",
    "ax1.set_title('LOSS v/s Iteration')    \n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(folddf4[0],folddf4[3],label = \"TRAIN Accuracy\") \n",
    "ax2.plot(folddf4[0],folddf4[4],label = \"TEST Accuracy\")\n",
    "ax2.set_title('Accuracy v/s Iteration')   \n",
    "ax2.set_xlabel('Iteration')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "fig.suptitle('For Fold 3')\n",
    "\n",
    "#loss1train = model.lossf(dfY4,Y_train4)\n",
    "#loss1test = model.lossf(Yfold3,Y_pred4)\n",
    "#acc1train = model.acc(dfY4,Y_train4)\n",
    "#acc1test = model.acc(Yfold3,Y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = LogRegression(0.001,1000)   \n",
    "dfX5 = pd.concat([Xfold5,Xfold1,Xfold2,Xfold3], ignore_index=True)\n",
    "dfY5 = pd.concat([Yfold5,Yfold1,Yfold2,Yfold3], ignore_index=True)\n",
    "dfY5 = dfY5.to_numpy().reshape(4000)\n",
    "loss_trlist,accu_trlist = model5.fit(dfX5.to_numpy(), dfY5)  \n",
    "Y_train5 = model5.predict(dfX5.to_numpy())\n",
    "Y_pred5 = model5.predict(Xfold4.to_numpy())\n",
    "\n",
    "Y4 = Yfold4\n",
    "Y4 = Y4.to_numpy().reshape(1000)\n",
    "loss_tslist,accu_tslist = model4.fit(Xfold4.values,Y4)\n",
    "\n",
    "folddf5 = np.column_stack((i,loss_trlist,loss_tslist,accu_trlist,accu_tslist))\n",
    "folddf5 = pd.DataFrame(folddf1)\n",
    "folddf5.columns = [0, 1,2,3,4]\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(10)\n",
    "ax1.plot(folddf5[0],folddf5[1],label = \"TRAIN LOSS\") \n",
    "ax1.plot(folddf5[0],folddf5[2],label = \"TEST LOSS\")\n",
    "ax1.set_title('LOSS v/s Iteration')    \n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(folddf5[0],folddf5[3],label = \"TRAIN Accuracy\") \n",
    "ax2.plot(folddf5[0],folddf5[4],label = \"TEST Accuracy\")\n",
    "ax2.set_title('Accuracy v/s Iteration')   \n",
    "ax2.set_xlabel('Iteration')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "fig.suptitle('For Fold 4')\n",
    "#loss1train = model.lossf(dfY5,Y_train5)\n",
    "#loss1test = model.lossf(Yfold4,Y_pred5)\n",
    "#acc1train = model.acc(dfY5,Y_train5)\n",
    "#acc1test = model.acc(Yfold4,Y_pred5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list2=[]  \n",
    "from sklearn import metrics\n",
    "list2.append((5,metrics.accuracy_score(Y_train1, dfY1),metrics.accuracy_score(Y_pred1, Yfold5)))\n",
    "list2.append((1,metrics.accuracy_score(Y_train2, dfY2),metrics.accuracy_score(Y_pred2, Yfold1)))\n",
    "list2.append((2,metrics.accuracy_score(Y_train3, dfY3),metrics.accuracy_score(Y_pred3, Yfold2)))\n",
    "list2.append((3,metrics.accuracy_score(Y_train4, dfY4),metrics.accuracy_score(Y_pred4, Yfold3)))\n",
    "list2.append((4,metrics.accuracy_score(Y_train5, dfY5),metrics.accuracy_score(Y_pred5, Yfold4)))\n",
    "        \n",
    "df2 = DataFrame(list2,columns=['Fold','Train Accuracy','Test Accuracy'])\n",
    "print(df2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
